{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here we would like to perform some analysis with the IBL pipeline.\n",
    "\n",
    "First thing first, let's **import the IBL pipeline package**, and a few other useful packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibl_pipeline import subject, acquisition, action, behavior, reference, ephys\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from uuid import UUID\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A simple example: compute the firing rate of each cluster across one session**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look of the ephys schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(ephys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ephys sessions do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.Ephys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ephys sessions with clustering results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.Ephys & ephys.Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then pick one ephys session to focus on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_session = ephys.Ephys & {'subject_uuid': UUID('077d4b11-c784-4cb9-983c-5a596815434f')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of clusters in this session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.Cluster & ephys_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = ephys.Cluster & ephys_session & 'cluster_id=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need to compute the firing rate of each cluster?  \n",
    "1. Total spike number  \n",
    "2. Recording time length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total spike number\n",
    "spk_times = cluster.fetch1('cluster_spike_times')\n",
    "total_spk_num = len(spk_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session duration\n",
    "session_duration = (acquisition.Session & cluster).proj(\n",
    "    session_duration='session_end_time - session_start_time').fetch1('session_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute firing rate \n",
    "fr = total_spk_num/session_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We got the firing rate!  \n",
    "The next question is, how do we save it in the database?  \n",
    "Put the entry in a table!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own schema and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we would like to do is to create a schema with `dj.schema`.  \n",
    "**Note**: the schema name you create has to either start with `user_{your user name}`, which is only accessible by you, or start with `group_share_`, which is accessible by the entire group. Here we use our user_name  \n",
    "**Note 2**: if your user_name contains a `.`, such as `miles.wells`, please delete it (`mileswells`) when creating the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('user_shan_tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the new schema is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a **manual** table to save the firing rate result.  \n",
    "A class created with DataJoint correponds to a table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class FiringRateManual(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> ephys.Cluster         # Each cluster has a firing rate\n",
    "    ---\n",
    "    firing_rate:     float   # Hz\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the brand-new table we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateManual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, sure, it's emtpy. We haven't inserted anything into it.  \n",
    "Now let's insert the firing rate we just computed into this empty table.  \n",
    "We need to insert the entry with all fields defined in the table, usually in a format of dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firing rate entry needs to inherit all primary keys from ephys.Cluster\n",
    "cluster_key = cluster.fetch1('KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_entry = dict(\n",
    "    **cluster_key,\n",
    "    firing_rate=fr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now insert it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateManual.insert1(firing_rate_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the table again to see what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateManual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool the entry is there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can of course write a for loop to compute all fr and insert them one by one, but that's too slow. We can compute the results and insert them all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the first 30 clusters and insert one by one, and compute time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for icluster in (ephys.Cluster & 'cluster_id between 1 and 30' & ephys_session).fetch('KEY'):\n",
    "    spk_times = (ephys.Cluster & icluster).fetch1('cluster_spike_times')\n",
    "    fr_entry = dict(**icluster,\n",
    "                    firing_rate=len(spk_times)/session_duration)\n",
    "    FiringRateManual.insert1(fr_entry)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the next 30 clusters and insert all at once as a list of dictionaries!\n",
    "start_time = time.time()\n",
    "\n",
    "fr_entries = []\n",
    "for icluster in (ephys.Cluster & 'cluster_id between 31 and 60' & ephys_session).fetch('KEY'):\n",
    "    spk_times = (ephys.Cluster & icluster).fetch1('cluster_spike_times')\n",
    "    fr_entry = dict(**icluster,\n",
    "                    firing_rate=len(spk_times)/session_duration)\n",
    "    fr_entries.append(fr_entry)\n",
    "    \n",
    "FiringRateManual.insert(fr_entries)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we will need to remember which clusters has been computed and inserted. If we insert the same entry twice, there will be an error. For example, let's rerun the above cell. We can overcome that problem by add the argument `skip_duplicates=True` inside `.insert()` or `.insert1()`, but it is not a very elegant solution.  \n",
    "The best approach here is to use a **Computed** table, it has the exact definition as the previous manual table, but with a magic **make** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class FiringRateComputed(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> ephys.Cluster         # Each cluster has a firing rate\n",
    "    ---\n",
    "    firing_rate:     float   # Hz\n",
    "    \"\"\"\n",
    "    def make(self, key):\n",
    "        session_duration = (acquisition.Session & key).proj(\n",
    "            session_duration='session_end_time - session_start_time').fetch1('session_duration')\n",
    "        \n",
    "        spk_times = (ephys.Cluster & key).fetch1('cluster_spike_times')\n",
    "        firing_rate_entry = dict(**key, firing_rate=len(spk_times)/session_duration)\n",
    "        self.insert1(firing_rate_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can `populate` the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateComputed.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateComputed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `populate` do?** \n",
    "\n",
    "It does two major things:  \n",
    "1. From the table definition, get the keys that needs to computed, which we called `key_source`. By default, it would be the join result of the primary dependent tables minus the once has been computed.  \n",
    "2. Call `make` function defined in the class, and compute one by one, with each individual key from the `key_source`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we still have to insert one by one, which is a bit slow. How do we do the trick of insert all firing rate of clusters in one session together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the `key_source` by redefining it to a larger scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class FiringRateComputedFromSession(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> ephys.Cluster         # Each cluster has a firing rate\n",
    "    ---\n",
    "    firing_rate:     float   # Hz\n",
    "    \"\"\"\n",
    "    key_source = ephys.Ephys & ephys.Cluster  # populate for each ephys data set where clustering is available.\n",
    "    \n",
    "    def make(self, key): # the key here is now the primary key of ephys.Ephys, instead of ephys.Cluster\n",
    "        session_duration = (acquisition.Session & key).proj(\n",
    "            session_duration='session_end_time - session_start_time').fetch1('session_duration')\n",
    "        \n",
    "        fr_entries = []\n",
    "        for icluster in (ephys.Cluster & key).fetch('KEY'):\n",
    "            spk_times = (ephys.Cluster & icluster).fetch1('cluster_spike_times')\n",
    "            fr_entry = dict(**icluster,\n",
    "                            firing_rate=len(spk_times)/session_duration)\n",
    "            fr_entries.append(fr_entry)\n",
    "    \n",
    "        self.insert(fr_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateComputedFromSession.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete entries and drop a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(FiringRateManual & 'cluster_id=0').delete() # any restrictor would work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiringRateManual.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: How to work with data where you don't have the code to generate the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anne_analyses = dj.create_virtual_module('analyses', 'group_shared_anneurai_analyses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anne_analyses.Age()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
